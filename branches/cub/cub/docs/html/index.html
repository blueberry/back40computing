<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>CUB: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="extra_stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">CUB
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.2 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Groups</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">CUB Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#sec1">(1) What is CUB?</a></li>
<li class="level1"><a href="#sec2">(2) A simple example</a></li>
<li class="level1"><a href="#sec3">(3) Why do you need CUB?</a></li>
<li class="level1"><a href="#sec4">(4) How does CUB work?</a><ul><li class="level2"><a href="#sec3sec1">4.1 &nbsp;&nbsp; C++ templates</a></li>
<li class="level2"><a href="#sec3sec2">4.2 &nbsp;&nbsp; Reflective type structure</a></li>
<li class="level2"><a href="#sec3sec3">4.3 &nbsp;&nbsp; Flexible data arrangement among threads</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="sec1"></a>
(1) What is CUB?</h1>
<dl class="section user"><dt></dt><dd>CUB is a library of high performance SIMT primitives for CUDA kernel programming. CUB enhances productivity and portability by providing commonplace CTA-wide, warp-wide, and thread-level operations that are flexible and tunable to fit your kernel needs.</dd></dl>
<dl class="section user"><dt></dt><dd>Browse our collections of:<ul>
<li><a href="annotated.html"><b>SIMT cooperative primitives</b></a><ul>
<li>CtaRadixSort, CtaReduce, WarpScan, etc.</li>
</ul>
</li>
<li><a href="group___simt_utils.html"><b>SIMT utilities</b></a><ul>
<li>CTA loads/stores in blocked/striped arrangements (vectorized, coalesced, etc.)</li>
<li>Sequential ThreadScan, ThreadReduce, etc.</li>
<li>Cache-modified ThreadLoad/ThreadStore</li>
</ul>
</li>
<li><a href="group___host_util.html"><b>Host utilities</b></a><ul>
<li>Caching allocators, error handling, etc.</li>
</ul>
</li>
</ul>
</dd></dl>
<h1><a class="anchor" id="sec2"></a>
(2) A simple example</h1>
<dl class="section user"><dt></dt><dd>The following kernel snippet illustrates how easy it is to compose CUB's scan and data-movement primitives into a single kernel for computing prefix sum:</dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub.cuh</a>&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// An exclusive prefix sum kernel (assuming only a single CTA)</span></div>
<div class="line"><span class="keyword">template</span> &lt;</div>
<div class="line">     <span class="keywordtype">int</span>         CTA_THREADS,                        <span class="comment">// Threads per CTA</span></div>
<div class="line">     <span class="keywordtype">int</span>         ITEMS_PER_THREAD,                   <span class="comment">// Items per thread</span></div>
<div class="line">     <span class="keyword">typename</span>    T&gt;                                  <span class="comment">// Data type</span></div>
<div class="line">__global__ <span class="keywordtype">void</span> PrefixSumKernel(T *d_in, T *d_out)</div>
<div class="line">{</div>
<div class="line">     <span class="keyword">using namespace </span>cub;</div>
<div class="line"></div>
<div class="line">     <span class="comment">// Parameterize a CtaScan type for use in the current problem context</span></div>
<div class="line">     <span class="keyword">typedef</span> <a class="code" href="classcub_1_1_cta_scan.html" title="The CtaScan type provides variants of parallel prefix scan across threads within a CTA...">CtaScan&lt;T, CTA_THREADS&gt;</a> CtaScan;</div>
<div class="line"></div>
<div class="line">     <span class="comment">// The shared memory for CtaScan</span></div>
<div class="line">     __shared__ <span class="keyword">typename</span> <a class="code" href="classcub_1_1_cta_scan.html#a98037d2e1f2390059ef8f7d97493f805" title="The operations exposed by CtaScan require shared memory of this type. This opaque storage can be allo...">CtaScan::SmemStorage</a> smem_storage;</div>
<div class="line"></div>
<div class="line">     <span class="comment">// A segment of data items per thread</span></div>
<div class="line">     T data[ITEMS_PER_THREAD];</div>
<div class="line"></div>
<div class="line">     <span class="comment">// Load a tile of data using vector-load instructions</span></div>
<div class="line">     <a class="code" href="group___simt_utils.html#gaba3b58962601c11d7bc2c0addd08565b" title="Load a tile of items across CTA threads directly using the specified cache modifier.">CtaLoadVectorized</a>(data, d_in, 0);</div>
<div class="line"></div>
<div class="line">     <span class="comment">// Perform an exclusive prefix sum across the tile of data</span></div>
<div class="line">     <a class="code" href="classcub_1_1_cta_scan.html#ac9ab13964a6e3a6e639b61f46ac53eda" title="Computes an exclusive CTA-wide prefix scan using addition (+) as the scan operator. Each thread contributes one input element. The inclusive CTA-wide aggregate of all inputs is computed for thread0.">CtaScan::ExclusiveSum</a>(smem_storage, data, data);</div>
<div class="line"></div>
<div class="line">     <span class="comment">// Store a tile of data using vector-load instructions</span></div>
<div class="line">     <a class="code" href="group___simt_utils.html#ga175a94f15417edb776706412b31dc019" title="Store a tile of items across CTA threads directly using the specified cache modifier.">CtaStoreVectorized</a>(data, d_out, 0);</div>
<div class="line">}</div>
</div><!-- fragment --></dd></dl>
<dl class="section user"><dt></dt><dd>The <a class="el" href="classcub_1_1_cta_scan.html" title="The CtaScan type provides variants of parallel prefix scan across threads within a CTA...">cub::CtaScan</a> primitive implements an efficient prefix sum across CTA threads that is specialized to the underlying architecture. It is parameterized by the number of CTA threads and the aggregate data type <code>T</code>. Once instantiated, it exposes the opaque <a class="el" href="classcub_1_1_cta_scan.html#a98037d2e1f2390059ef8f7d97493f805" title="The operations exposed by CtaScan require shared memory of this type. This opaque storage can be allo...">cub::CtaScan::SmemStorage</a> type which allows us to allocate the shared memory needed by the primitive.</dd></dl>
<dl class="section user"><dt></dt><dd>Furthermore, the kernel uses CUB's primitives for vectorizing global loads and stores. For example, <code>ld.global.v4.s32</code> will be generated when <code>T</code> = <code>int</code> and <code>ITEMS_PER_THREAD</code> is a multiple of 4.</dd></dl>
<h1><a class="anchor" id="sec3"></a>
(3) Why do you need CUB?</h1>
<dl class="section user"><dt></dt><dd>With the exception of CUB, there are few (if any) software libraries of reusable CTA-level primitives. This is unfortunate, especially for complex algorithms with intricate dependences between threads. For cooperative problems, the SIMT kernel is often the most complex and performance-sensitive layer in the CUDA software stack. Best practices would have us leverage libraries and abstraction layers to help mitigate the complexity, risks, and maintenance costs of this software.</dd></dl>
<dl class="section user"><dt></dt><dd>As a SIMT library and software abstraction layer, CUB gives you:<ol type="1">
<li><b>The ease of sequential programming.</b> Parallel primitives within kernels can be simply sequenced together (similar to Thrust programming on the host).</li>
<li><b>The benefits of transparent performance-portability.</b> Kernels can be simply recompiled against new CUB releases (instead of hand-rewritten) to leverage new algorithmic developments, hardware instructions, etc.</li>
</ol>
</dd></dl>
<h1><a class="anchor" id="sec4"></a>
(4) How does CUB work?</h1>
<dl class="section user"><dt></dt><dd>CUB leverages the following programming idioms:<ol type="1">
<li><a href="index.html#sec3sec1"><b>C++ templates</b></a></li>
<li><a href="index.html#sec3sec2"><b>Reflective type structure</b></a></li>
<li><a href="index.html#sec3sec3"><b>Flexible data arrangement among threads</b></a></li>
</ol>
</dd></dl>
<h2><a class="anchor" id="sec3sec1"></a>
4.1    C++ templates</h2>
<dl class="section user"><dt></dt><dd>As a SIMT library, CUB must be flexible enough to accommodate a wide spectrum of <em>problem contexts</em>, i.e., specific:<ul>
<li>Data types</li>
<li>Widths of parallelism (CTA threads)</li>
<li>Grain sizes (data items per thread)</li>
<li>Underlying architectures (special instructions, warp width, rules for bank conflicts, etc.)</li>
<li>Tuning requirements (e.g., latency vs. throughput)</li>
</ul>
</dd></dl>
<dl class="section user"><dt></dt><dd>To provide this flexibility, CUB is implemented as a C++ template library. C++ templates are a way to write generic algorithms and data structures. There is no need to build CUB separately. You simply #<code>include</code> the <code><a class="el" href="cub_8cuh.html">cub.cuh</a></code> header file into your <code>.cu</code> or <code>.cpp</code> sources and compile with CUDA's <code>nvcc</code> compiler.</dd></dl>
<h2><a class="anchor" id="sec3sec2"></a>
4.2    Reflective type structure</h2>
<dl class="section user"><dt></dt><dd>Cooperation requires shared memory for communicating between threads. However, the specific size and layout of the memory needed by a given primitive will be specific to the details of its problem context (e.g., how many threads are calling into it, how many items per thread, etc.). Furthermore, this shared memory must be allocated externally to the component if it is to be reused elsewhere by the CTA.</dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="comment">// Parameterize a CtaRadixSort type for use with 128 threads</span></div>
<div class="line"><span class="comment">// and 4 items per thread</span></div>
<div class="line"><span class="keyword">typedef</span> <a class="code" href="classcub_1_1_cta_radix_sort.html" title="The CtaRadixSort type provides variants of parallel radix sorting of unsigned numeric types across th...">cub::CtaRadixSort&lt;unsigned int, 128, 4&gt;</a> CtaRadixSort;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare shared memory for CtaRadixSort</span></div>
<div class="line">__shared__ <span class="keyword">typename</span> CtaRadixSort::SmemStorage smem_storage;</div>
<div class="line"></div>
<div class="line"><span class="comment">// A segment of consecutive input items per thread</span></div>
<div class="line"><span class="keywordtype">int</span> keys[4];</div>
<div class="line"></div>
<div class="line"><span class="comment">// Obtain keys in blocked order</span></div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Sort keys in ascending order</span></div>
<div class="line">CtaRadixSort::SortBlocked(smem_storage, keys);</div>
</div><!-- fragment --></dd></dl>
<dl class="section user"><dt></dt><dd>To address this issue, we encapsulate cooperative procedures within <em>reflective type structure</em> (C++ classes). As illustrated in the <a class="el" href="classcub_1_1_cta_radix_sort.html" title="The CtaRadixSort type provides variants of parallel radix sorting of unsigned numeric types across th...">cub::CtaRadixSort</a> example above, these primitives are C++ classes with interfaces that expose both (1) procedural methods as well as (2) the opaque shared memory types needed for their operation.</dd></dl>
<h2><a class="anchor" id="sec3sec3"></a>
4.3    Flexible data arrangement among threads</h2>
<dl class="section user"><dt></dt><dd>We often design kernels such that each CTA is assigned a "tile" of data items for processing. When the tile size is equal to the CTA size, the mapping of data onto threads is straightforward (1:1 items to CTA threads). However, it is often desirable to design a tile size that is a constant factor larger than the CTA size. In this case, each thread is assigned multiple data items. The benefits of doing so include:<ul>
<li><b>Algorithmic efficiency</b>. Sequential work over multiple items in thread-private registers is cheaper than synchronized, cooperative work through shared memory spaces</li>
<li><b>Data occupancy</b>. The number of items that can be resident on-chip in thread-private register storage is often greater than the number of schedulable threads</li>
<li><b>Instruction-level parallelism</b>. Multiple items per thread also facilitates greater ILP for improved throughput and utilization</li>
</ul>
</dd></dl>
<dl class="section user"><dt></dt><dd>When tile size is greater than CTA size, we are faced with the question how tile items should partitioned among CTA threads. For linearly-ordered tiles, CUB supports the following two arrangement patterns:<ul>
<li><b><em>Blocked</em> arrangement</b>. The aggregate tile of items is partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</li>
<li><b><em>Striped</em> arrangement</b>. The aggregate tile of items is partitioned across threads in "striped" fashion, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>CTA_THREADS</code> between them. <br/>
<br/>
 <div class="image">
<img src="thread_data_1.png" alt="thread_data_1.png"/>
</div>
 <center><b>Blocked vs. striped arrangements with <code>CTA_THREADS</code> = 4 and <code>ITEMS_PER_THREAD</code> = 2</b></center> <br/>
</li>
</ul>
</dd></dl>
<dl class="section user"><dt></dt><dd>The <a class="el" href="classcub_1_1_cta_exchange.html" title="The CtaExchange type provides operations for reorganizing the partitioning of ordered data across CTA...">cub::CtaExchange</a> primitive provides operations for converting between blocked and striped arrangements. Blocked arrangements are often desirable for algorithmic benefits (where long sequences of items can be processed sequentially within each thread). Striped arrangements are often desirable for data movement through global memory (where read/write coalescing is a important performance consideration). <br/>
<br/>
 <div class="image">
<img src="thread_data_2.png" alt="thread_data_2.png"/>
</div>
 <center><b>Exchanging items between blocked vs. striped arrangements (illustrated as a 2D transpose with <code>CTA_THREADS</code> = 8 and <code>ITEMS_PER_THREAD</code> = 4)</b></center> <br/>
</dd></dl>
<dl class="section user"><dt></dt><dd>We can also illustrate these arrangements as two dimensional representations (items-per-thread vs. threads-per-CTA). In this form, we see that conversions between the two arrangements are isomorphic to 2D matrix transpose operations. </dd></dl>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Jan 30 2013 08:55:39 for CUB by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.2
</small></address>
</body>
</html>
